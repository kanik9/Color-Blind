{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as c\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "import keras \n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import imageio\n",
    "\n",
    "training_paths = pathlib.Path('/home/kanik/Documents/dataset3/images/').glob('*.jpg')\n",
    "training_sorted = sorted([str(x) for x in training_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Test data Extraction complete\n"
     ]
    }
   ],
   "source": [
    "green_count = 0\n",
    "red_count = 0\n",
    "other_count = 0\n",
    "training_size = 100\n",
    "test_size = 70\n",
    "training_images = []\n",
    "test_images = []\n",
    "training_labels =[]\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "\n",
    "green_dir_train  ='/home/kanik/Documents/dataset3/color_green/train/green/'\n",
    "red_dir_train = '/home/kanik/Documents/dataset3/color_red/train/red/'\n",
    "green_dir_val = '/home/kanik/Documents/dataset3/color_green/validation/green'\n",
    "red_dir_val = '/home/kanik/Documents/dataset3/color_red/validation/red'\n",
    "other_dir_train  ='/home/kanik/Documents/dataset3/color_other/train/other/'\n",
    "other_dir_val = '/home/kanik/Documents/dataset3/color_other/validation/other'\n",
    "\n",
    "\n",
    "make_dir(green_dir_train)\n",
    "make_dir(red_dir_train)\n",
    "make_dir(green_dir_val)\n",
    "make_dir(red_dir_val)\n",
    "make_dir(other_dir_train)\n",
    "make_dir(other_dir_val)\n",
    "\n",
    "def getZeros(number):\n",
    "    if(number>10 and number<100):\n",
    "        return \"0\"\n",
    "    if (number<10):\n",
    "        return \"00\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "for i , file in enumerate(training_sorted):\n",
    "    if training_sorted[i][38] == 'g':\n",
    "        if green_count >=training_size+test_size:\n",
    "            continue\n",
    "        else :\n",
    "            image = c.imread(file)\n",
    "            #image = c.resize(image,(size,size),interpolation = c.INTER_AREA)\n",
    "            if green_count < training_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(0)\n",
    "                zeros = getZeros(green_count)\n",
    "                c.imwrite(green_dir_train + 'green' +str(zeros)+str(green_count)+'.jpg',image)\n",
    "            if green_count >=training_size and green_count <training_size+test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(0)\n",
    "                zeros = getZeros(green_count - 1000)\n",
    "                c.imwrite(green_dir_val + 'green' +str(zeros)+str(green_count)+'.jpg',image)\n",
    "        green_count +=1\n",
    "    if training_sorted[i][38] == 'r':\n",
    "        if red_count >=training_size+test_size:\n",
    "            continue\n",
    "        else :\n",
    "            image = c.imread(file)\n",
    "            #image = c.resize(image,(size,size),interpolation = c.INTER_AREA)\n",
    "            if red_count < training_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(1)\n",
    "                zeros = getZeros(red_count)\n",
    "                c.imwrite(red_dir_train + 'red' +str(zeros)+str(red_count)+'.jpg',image)\n",
    "            if red_count >=training_size and red_count <training_size+test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(1)\n",
    "                zeros = getZeros(red_count - 1000)\n",
    "                c.imwrite(red_dir_val + \"red\" +str(zeros)+str(red_count)+'.jpg',image)\n",
    "        red_count +=1\n",
    "    \n",
    "    if training_sorted[i][38] == 'o':\n",
    "        if other_count >=training_size+test_size:\n",
    "            continue\n",
    "        else :\n",
    "            image = c.imread(file)\n",
    "            #image = c.resize(image,(size,size),interpolation = c.INTER_AREA)\n",
    "            if other_count < training_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(2)\n",
    "                zeros = getZeros(other_count)\n",
    "                c.imwrite(other_dir_train + 'other' +str(zeros)+str(other_count)+'.jpg',image)\n",
    "            if other_count >=training_size and other_count <training_size+test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(2)\n",
    "                zeros = getZeros(other_count - 1000)\n",
    "                c.imwrite(other_dir_val + \"other\" +str(zeros)+str(other_count)+'.jpg',image)\n",
    "        other_count +=1\n",
    "                \n",
    "\n",
    "    if green_count == training_size+test_size+1 and red_count == training_size+test_size+1 and other_count == training_size+test_size+1:\n",
    "        break\n",
    "        \n",
    "print('Training and Test data Extraction complete')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('red_vs_green_vs_other_training_data.npz',np.array(training_images))\n",
    "np.savez('red_vs_green_vs_other_training_labels.npz',np.array(training_labels))\n",
    "np.savez('red_vs_green_vs_other_test_data.npz',np.array(test_images))\n",
    "np.savez('red_vs_green_vs_other_test_labels.npz',np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_training_and_test(datasetname):\n",
    "    npzfile = np.load(datasetname + '_training_data.npz')\n",
    "    train = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load(datasetname + '_training_labels.npz')\n",
    "    train_labels = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load(datasetname + '_test_data.npz')\n",
    "    test = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load(datasetname + '_test_labels.npz')\n",
    "    test_labels = npzfile['arr_0']\n",
    "    \n",
    "    \n",
    "    return(train,train_labels),(test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-green\n",
      "2-green\n",
      "3-red\n",
      "4-other\n",
      "5-other\n",
      "6-green\n",
      "7-other\n",
      "8-red\n",
      "9-other\n",
      "10-red\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    random = np.random.randint(0,len(training_images))\n",
    "    c.imshow('image_'+str(i),training_images[random])\n",
    "    if training_labels[random] ==1:\n",
    "        print(str(i)+'-red')\n",
    "    elif training_labels[random] ==0 :\n",
    "        print(str(i)+'-green')\n",
    "    else :\n",
    "        print(str(i)+'-other')\n",
    "    c.waitKey(0)\n",
    "    \n",
    "c.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1, 1, 3)\n",
      "(300, 3)\n",
      "(210, 1, 1, 3)\n",
      "(210, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "batch_size=16\n",
    "epochs=15\n",
    "(x_train,y_train),(x_test,y_test)=load_data_training_and_test('red_vs_green_vs_other')\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "#y_train=y_train.reshape(y_train.shape[0],1)\n",
    "#y_test=y_test.reshape(y_test.shape[0],1)\n",
    "y_train=np_utils.to_categorical(y_train)\n",
    "y_test=np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train/=255\n",
    "x_test/=255\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 21:24:05.126200 139879870719808 deprecation_wrapper.py:119] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0726 21:24:05.145822 139879870719808 deprecation_wrapper.py:119] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0726 21:24:05.149250 139879870719808 deprecation_wrapper.py:119] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0726 21:24:05.207322 139879870719808 deprecation_wrapper.py:119] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0726 21:24:05.210861 139879870719808 deprecation_wrapper.py:119] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0726 21:24:05.219039 139879870719808 deprecation.py:506] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0726 21:24:05.327800 139879870719808 deprecation_wrapper.py:119] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0726 21:24:05.336919 139879870719808 deprecation_wrapper.py:119] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1, 1, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 64)          2112      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 10,947\n",
      "Trainable params: 10,947\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "model=Sequential() #use to make layers\n",
    "model.add(Conv2D(32,kernel_size=(1,1),activation='relu',input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64,(1,1),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=SGD(0.01),metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 21:24:06.223574 139879870719808 deprecation.py:323] From /home/kanik/anaconda3/envs/PythonCPU/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 210 samples\n",
      "Epoch 1/15\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.0980 - acc: 0.3467 - val_loss: 1.0583 - val_acc: 0.6667\n",
      "Epoch 2/15\n",
      "300/300 [==============================] - 0s 971us/step - loss: 1.0601 - acc: 0.5000 - val_loss: 1.0371 - val_acc: 1.0000\n",
      "Epoch 3/15\n",
      "300/300 [==============================] - 0s 842us/step - loss: 1.0328 - acc: 0.6367 - val_loss: 1.0166 - val_acc: 0.9333\n",
      "Epoch 4/15\n",
      "300/300 [==============================] - 0s 823us/step - loss: 1.0053 - acc: 0.7033 - val_loss: 0.9983 - val_acc: 0.9333\n",
      "Epoch 5/15\n",
      "300/300 [==============================] - 0s 881us/step - loss: 0.9869 - acc: 0.7833 - val_loss: 0.9798 - val_acc: 0.8762\n",
      "Epoch 6/15\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9597 - acc: 0.7933 - val_loss: 0.9603 - val_acc: 0.8333\n",
      "Epoch 7/15\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9429 - acc: 0.8300 - val_loss: 0.9406 - val_acc: 0.8000\n",
      "Epoch 8/15\n",
      "300/300 [==============================] - 0s 937us/step - loss: 0.9073 - acc: 0.8567 - val_loss: 0.9186 - val_acc: 0.8000\n",
      "Epoch 9/15\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.8754 - acc: 0.8667 - val_loss: 0.8939 - val_acc: 0.8000\n",
      "Epoch 10/15\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8556 - acc: 0.8467 - val_loss: 0.8698 - val_acc: 0.8000\n",
      "Epoch 11/15\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8028 - acc: 0.9367 - val_loss: 0.8444 - val_acc: 0.8000\n",
      "Epoch 12/15\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7732 - acc: 0.9100 - val_loss: 0.8168 - val_acc: 0.8000\n",
      "Epoch 13/15\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.7479 - acc: 0.9067 - val_loss: 0.7906 - val_acc: 0.8000\n",
      "Epoch 14/15\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7241 - acc: 0.9067 - val_loss: 0.7635 - val_acc: 0.8000\n",
      "Epoch 15/15\n",
      "300/300 [==============================] - 0s 911us/step - loss: 0.6789 - acc: 0.9067 - val_loss: 0.7373 - val_acc: 0.8000\n",
      "Test losses 0.7372662419364566\n",
      "Test accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test,y_test))\n",
    "#batch size here is how many nodes in hidden layer\n",
    "score=model.evaluate(x_test,y_test,verbose=0)\n",
    "print('Test losses',score[0])\n",
    "print('Test accuracy',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('colors.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<class 'str'>\n",
      "red\n",
      "1\n",
      "<class 'str'>\n",
      "red\n",
      "1\n",
      "<class 'str'>\n",
      "red\n",
      "1\n",
      "<class 'str'>\n",
      "red\n",
      "1\n",
      "<class 'str'>\n",
      "red\n",
      "1\n",
      "<class 'str'>\n",
      "red\n",
      "2\n",
      "<class 'str'>\n",
      "others\n",
      "1\n",
      "<class 'str'>\n",
      "red\n",
      "0\n",
      "<class 'str'>\n",
      "green\n",
      "0\n",
      "<class 'str'>\n",
      "green\n"
     ]
    }
   ],
   "source": [
    "classifier = load_model('colors.h5')\n",
    "\n",
    "def draw_test(name, pred, input_im):\n",
    "    print(pred)\n",
    "    BLACK = [0,0,0]\n",
    "    print(type(pred))\n",
    "    if pred == \"0\":\n",
    "        pred = \"green\"\n",
    "    if pred == \"1\":\n",
    "        pred = \"red\"\n",
    "    if pred == \"2\":\n",
    "        pred = \"others\"\n",
    "    print(pred)\n",
    "    '''   \n",
    "    expanded_image = cv2.copyMakeBorder(input_im, 0, 0, 0, imageL.shape[0] ,\n",
    "                                        cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    #expanded_image = cv2.cvtColor(expanded_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.putText(expanded_image, str(pred), (252, 70) , \n",
    "                cv2.FONT_HERSHEY_COMPLEX_SMALL,4, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "    '''\n",
    "\n",
    "for i in range(0,10):\n",
    "    rand = np.random.randint(0,len(x_test))\n",
    "    input_im = x_test[rand]\n",
    "\n",
    "    imageL = cv2.resize(input_im, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imshow(\"Test Image\", imageL)\n",
    "\n",
    "    input_im = input_im.reshape(1,1,1,3) \n",
    "    \n",
    "    ## Get Prediction\n",
    "    res = str(classifier.predict_classes(input_im, 1, verbose = 0)[0])\n",
    "\n",
    "    draw_test(\"Prediction\", res,input_im) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model('colors.h5')\n",
    "def new(fr):\n",
    "    global classifier\n",
    "    res = str(classifier.predict_classes(fr, 1, verbose = 0)[0])\n",
    "    #print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20243\n",
      "9502\n",
      "20689\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "\n",
    "img=cv2.imread('/home/kanik/Downloads/image.jpg')\n",
    "row=img.shape[0]\n",
    "col=img.shape[1]\n",
    "red=0\n",
    "green=0\n",
    "others=0\n",
    "frame1 = img.astype('float32')\n",
    "frame1 /= 255\n",
    "for i in range(row):\n",
    "    for j in range(col):\n",
    "        a=new(frame1[i][j].reshape(1,1,1,3))\n",
    "        if(a=='0'):\n",
    "            green=green+1\n",
    "        elif(a=='1'):\n",
    "            red=red+1\n",
    "        elif(a=='2'):\n",
    "            others=others+1\n",
    "print(red)\n",
    "print(green)\n",
    "print(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from keras.models import load_model \n",
    "\n",
    "classifier=load_model('colors.h5')\n",
    "def draw_test(name, pred, input_im):\n",
    "    BLACK = [0,0,0]\n",
    "    if pred == \"[0]\":\n",
    "        pred = \"green\"\n",
    "    if pred == \"[1]\":\n",
    "        pred = \"red\"\n",
    "    if pred == \"[2]\":\n",
    "        pred==\"others\"\n",
    "    cv2.putText(input_im, str(pred), (180, 70) , \n",
    "                cv2.FONT_HERSHEY_COMPLEX_SMALL,2, (0,255,0), 2)\n",
    "    cv2.imshow(name,input_im)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "2\n",
      "(1, 1, 1, 3)\n",
      "2\n",
      "(1, 1, 1, 3)\n",
      "2\n",
      "(1, 1, 1, 3)\n",
      "2\n",
      "(1, 1, 1, 3)\n",
      "2\n",
      "(1, 1, 1, 3)\n",
      "2\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n",
      "(1, 1, 1, 3)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while cam.isOpened():\n",
    "    ret, frame= cam.read(0)\n",
    "    frames=cv2.resize(frame,(1,1),interpolation=cv2.INTER_AREA)\n",
    "    img_rows=frames[0].shape[0]\n",
    "    img_cols=frames[0].shape[1]\n",
    "    frames=frames.reshape(1,frames.shape[0],img_rows,img_cols)\n",
    "    frames=frames.astype('float32')\n",
    "    frames/=255\n",
    "\n",
    "    print(frames.shape)\n",
    "    \n",
    "    pred=str(classifier.predict_classes(frames,verbose=0)[0])\n",
    "    print(pred)\n",
    "    draw_test(\"prediction\",pred,frame)\n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        break\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model('colors.h5')\n",
    "def old(fr):\n",
    "    global classifier\n",
    "    res = str(classifier.predict_classes(fr, 1, verbose = 0)[0])\n",
    "    #print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strat\n",
      "480\n",
      "640\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "1st\n",
      "2nd\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "classifier=load_model('colors.h5')\n",
    "\n",
    "def f_fun(frames):\n",
    "    red=0\n",
    "    green=0\n",
    "    others=0\n",
    "    \n",
    "    #frames=frames.reshape(1,frames.shape[0],img_rows,img_cols)\n",
    "    #frames=cv2.resize(frame,(1,1),interpolation=cv2.INTER_AREA)\n",
    "    frames=frames.astype('float32')\n",
    "    frames/=255\n",
    "    img_rows=frames.shape[0]\n",
    "    img_cols=frames.shape[1]\n",
    "    print(img_rows)\n",
    "    print(img_cols)\n",
    "    for i in range(img_rows):\n",
    "        for j in range(img_cols):\n",
    "            a=old(frames[i][j].reshape(1,1,1,3))\n",
    "            if(a=='0'):\n",
    "                frames[i][j] = [0,1,0]\n",
    "            #elif(a=='1'):\n",
    "                #green=green+1\n",
    "            #elif(a=='2'):\n",
    "                #others=others+1\n",
    "        print('1st')\n",
    "    print('2nd')\n",
    "    #cv2.imshow('name',frames)\n",
    "    frames *= 255\n",
    "    frames = frames.astype('uint8')\n",
    "    return frames\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read(0)\n",
    "    cv2.imshow('Original',frame)\n",
    "    if cv2.waitKey(1)==ord('s'):\n",
    "        cv2.destroyAllWindows()\n",
    "        print('strat')\n",
    "        x = f_fun(frame)\n",
    "        print('completed')\n",
    "        cv2.imshow('x',x)\n",
    "        break\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
